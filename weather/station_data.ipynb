{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading station weather data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable future warning\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# other imports\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from meteostat import Stations, Daily\n",
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from datetime import date, datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacial Data\n",
    "Each weather station has coordinates attached with it. To be able to merge it with the SOEP data set these coordinates need to be converted to some other format. We use the nuts format for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup cache\n",
    "Stations.cache_dir = \"./prod/.meteostat/cache\"\n",
    "\n",
    "query = Stations()\n",
    "query.region(\"DE\")\n",
    "stations = query.fetch()\n",
    "stations.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"prod/weather.db\"\n",
    "con = create_engine(\"sqlite:///\"+path, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary station data\n",
    "cols = [\n",
    "    'id',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'elevation',\n",
    "    'daily_start',\n",
    "    'daily_end'\n",
    "]\n",
    "stations = stations[cols]\n",
    "stations.rename({'id':'station_id'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUTS_CODE_3</th>\n",
       "      <th>NUTS_NAME_3</th>\n",
       "      <th>geometry</th>\n",
       "      <th>NUTS_CODE_2</th>\n",
       "      <th>NUTS_NAME_2</th>\n",
       "      <th>NUTS_CODE_1</th>\n",
       "      <th>NUTS_NAME_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DE111</td>\n",
       "      <td>Stuttgart, Stadtkreis</td>\n",
       "      <td>POLYGON ((9.13452 48.85668, 9.14122 48.86183, ...</td>\n",
       "      <td>DE11</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>DE1</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE112</td>\n",
       "      <td>Böblingen</td>\n",
       "      <td>POLYGON ((8.96647 48.82980, 8.99216 48.83356, ...</td>\n",
       "      <td>DE11</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>DE1</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE113</td>\n",
       "      <td>Esslingen</td>\n",
       "      <td>POLYGON ((9.40973 48.53721, 9.39153 48.53014, ...</td>\n",
       "      <td>DE11</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>DE1</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE114</td>\n",
       "      <td>Göppingen</td>\n",
       "      <td>POLYGON ((9.91934 48.63977, 9.94730 48.63369, ...</td>\n",
       "      <td>DE11</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>DE1</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE115</td>\n",
       "      <td>Ludwigsburg</td>\n",
       "      <td>MULTIPOLYGON (((9.30157 48.95210, 9.31516 48.9...</td>\n",
       "      <td>DE11</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>DE1</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NUTS_CODE_3            NUTS_NAME_3  \\\n",
       "0       DE111  Stuttgart, Stadtkreis   \n",
       "1       DE112              Böblingen   \n",
       "2       DE113              Esslingen   \n",
       "3       DE114              Göppingen   \n",
       "4       DE115            Ludwigsburg   \n",
       "\n",
       "                                            geometry NUTS_CODE_2 NUTS_NAME_2  \\\n",
       "0  POLYGON ((9.13452 48.85668, 9.14122 48.86183, ...        DE11   Stuttgart   \n",
       "1  POLYGON ((8.96647 48.82980, 8.99216 48.83356, ...        DE11   Stuttgart   \n",
       "2  POLYGON ((9.40973 48.53721, 9.39153 48.53014, ...        DE11   Stuttgart   \n",
       "3  POLYGON ((9.91934 48.63977, 9.94730 48.63369, ...        DE11   Stuttgart   \n",
       "4  MULTIPOLYGON (((9.30157 48.95210, 9.31516 48.9...        DE11   Stuttgart   \n",
       "\n",
       "  NUTS_CODE_1        NUTS_NAME_1  \n",
       "0         DE1  Baden-Württemberg  \n",
       "1         DE1  Baden-Württemberg  \n",
       "2         DE1  Baden-Württemberg  \n",
       "3         DE1  Baden-Württemberg  \n",
       "4         DE1  Baden-Württemberg  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read shape files\n",
    "shape = [\n",
    "    gp.read_file(f\"./data/nuts5000/5000_NUTS{i}.shp\").to_crs(epsg=4326)\n",
    "    for i in range(1, 4)\n",
    "]\n",
    "\n",
    "# spacial join shape files. This is possible since nuts is hirarchical\n",
    "nuts:gp.GeoDataFrame\n",
    "nuts = shape[2].sjoin(shape[1], how=\"left\", lsuffix='3', rsuffix='2', predicate=\"within\")\\\n",
    "               .sjoin(shape[0], how=\"left\", rsuffix='1', predicate=\"within\")\n",
    "nuts.rename({\"NUTS_CODE\":\"NUTS_CODE_1\",\t\"NUTS_NAME\":\"NUTS_NAME_1\"}, inplace=True, axis=1)\n",
    "nuts.drop(\"NUTS_LEVEL_2 NUTS_LEVEL_3 NUTS_LEVEL index_2 index_1\".split(), inplace=True, axis=1)\n",
    "nuts.sort_index(inplace=True)\n",
    "nuts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create GeoDataFrame from stations\n",
    "x, y = stations[\"longitude\"], stations[\"latitude\"]\n",
    "stations[\"geometry\"] = gp.GeoSeries(map(Point, zip(x, y)))\n",
    "stations.drop([\"longitude\", \"latitude\"], axis=1, inplace=True)\n",
    "stations = gp.GeoDataFrame(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to database\n",
    "stations.to_sql('stationinfo', con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>elevation</th>\n",
       "      <th>daily_start</th>\n",
       "      <th>daily_end</th>\n",
       "      <th>geometry</th>\n",
       "      <th>NUTS_CODE_3</th>\n",
       "      <th>NUTS_NAME_3</th>\n",
       "      <th>NUTS_CODE_2</th>\n",
       "      <th>NUTS_NAME_2</th>\n",
       "      <th>NUTS_CODE_1</th>\n",
       "      <th>NUTS_NAME_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>10015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1952-05-01</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>POINT (7.90000 54.18330)</td>\n",
       "      <td>DEF09</td>\n",
       "      <td>Pinneberg</td>\n",
       "      <td>DEF0</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>DEF</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>10018</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2009-02-24</td>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>POINT (8.35000 54.91670)</td>\n",
       "      <td>DEF07</td>\n",
       "      <td>Nordfriesland</td>\n",
       "      <td>DEF0</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>DEF</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>10020</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1931-01-01</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>POINT (8.41670 55.01670)</td>\n",
       "      <td>DEF07</td>\n",
       "      <td>Nordfriesland</td>\n",
       "      <td>DEF0</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>DEF</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>10022</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1973-01-01</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>POINT (8.95000 54.80000)</td>\n",
       "      <td>DEF07</td>\n",
       "      <td>Nordfriesland</td>\n",
       "      <td>DEF0</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>DEF</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>10026</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1891-01-01</td>\n",
       "      <td>1974-06-30</td>\n",
       "      <td>POINT (9.15000 54.51670)</td>\n",
       "      <td>DEF07</td>\n",
       "      <td>Nordfriesland</td>\n",
       "      <td>DEF0</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>DEF</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     station_id  elevation daily_start  daily_end                  geometry  \\\n",
       "1230      10015        4.0  1952-05-01 2022-12-18  POINT (7.90000 54.18330)   \n",
       "1231      10018       16.0  2009-02-24 2022-04-25  POINT (8.35000 54.91670)   \n",
       "1232      10020       26.0  1931-01-01 2022-12-18  POINT (8.41670 55.01670)   \n",
       "1233      10022        7.0  1973-01-01 2022-12-18  POINT (8.95000 54.80000)   \n",
       "1234      10026       28.0  1891-01-01 1974-06-30  POINT (9.15000 54.51670)   \n",
       "\n",
       "     NUTS_CODE_3    NUTS_NAME_3 NUTS_CODE_2         NUTS_NAME_2 NUTS_CODE_1  \\\n",
       "1230       DEF09      Pinneberg        DEF0  Schleswig-Holstein         DEF   \n",
       "1231       DEF07  Nordfriesland        DEF0  Schleswig-Holstein         DEF   \n",
       "1232       DEF07  Nordfriesland        DEF0  Schleswig-Holstein         DEF   \n",
       "1233       DEF07  Nordfriesland        DEF0  Schleswig-Holstein         DEF   \n",
       "1234       DEF07  Nordfriesland        DEF0  Schleswig-Holstein         DEF   \n",
       "\n",
       "             NUTS_NAME_1  \n",
       "1230  Schleswig-Holstein  \n",
       "1231  Schleswig-Holstein  \n",
       "1232  Schleswig-Holstein  \n",
       "1233  Schleswig-Holstein  \n",
       "1234  Schleswig-Holstein  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spactial join with nuts data\n",
    "stations:gp.GeoDataFrame\n",
    "stations = stations.sjoin(nuts, how=\"inner\", predicate=\"within\")\n",
    "stations.drop(\"index_right\", axis=1, inplace=True)\n",
    "stations.sort_index(inplace=True)\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather data\n",
    "Now that we have all the spacial data the only thing left to do is to get the historical weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup cache\n",
    "Daily.cache_dir = \"./prod/.meteostat/cache\"\n",
    "Daily.max_age = 12000000 # approx 4 months cache time \n",
    "Daily.threads = 20\n",
    "\n",
    "# start end endtime of SOEP panel\n",
    "start = datetime(1985, 1, 1)\n",
    "end = datetime.combine(date.today(), datetime.min.time())\n",
    "\n",
    "def work(station):\n",
    "    s_id = station[\"station_id\"]\n",
    "    daily = Daily(s_id, start=start, end=end)\n",
    "    data = daily.fetch()\n",
    "    data['station_id'] = s_id\n",
    "    data.to_sql('station', con, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1116 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) table station has no column named station_id\n[SQL: INSERT INTO station (time, tavg, tmin, tmax, prcp, snow, wdir, wspd, wpgt, pres, tsun, station_id, \"1230\") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)]\n[parameters: (('1985-01-01 00:00:00.000000', 1.6, 0.4, 5.9, 0.5, 0.0, 103.0, 40.7, 73.1, 1007.3, 0.0, '10015', None), ('1985-01-02 00:00:00.000000', 0.2, -0.8, 0.9, 0.0, 0.0, 35.0, 28.8, 71.3, 1012.0, 60.0, '10015', None), ('1985-01-03 00:00:00.000000', -2.7, -4.5, 0.5, 0.0, 0.0, 24.0, 34.2, 73.8, 1010.7, 60.0, '10015', None), ('1985-01-04 00:00:00.000000', -4.1, -5.2, -3.4, 0.0, 0.0, 31.0, 41.0, 78.8, 1011.0, 90.0, '10015', None), ('1985-01-05 00:00:00.000000', -5.3, -6.1, -3.3, 0.0, 0.0, 49.0, 25.9, 59.4, 1016.6, 54.0, '10015', None), ('1985-01-06 00:00:00.000000', -5.7, -7.5, -3.9, 3.5, 10.0, 131.0, 34.6, 77.8, 1009.9, 0.0, '10015', None), ('1985-01-07 00:00:00.000000', -6.7, -8.0, -5.0, 0.0, 130.0, 46.0, 32.0, 77.4, 1017.6, 366.0, '10015', None), ('1985-01-08 00:00:00.000000', -4.7, -7.7, -3.3, 4.9, 100.0, 55.0, 16.6, 58.7, 1014.3, 174.0, '10015', None)  ... displaying 10 of 13856 total bound parameter sets ...  ('2022-12-07 00:00:00.000000', 4.2, 3.9, 4.3, None, None, 107.0, 25.1, 38.9, 1022.4, None, '10015', None), ('2022-12-08 00:00:00.000000', 4.6, 4.3, 4.9, None, None, 169.0, 25.9, 38.9, 1015.8, None, '10015', None))]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1880\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1879\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1880\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_executemany(\n\u001b[1;32m   1881\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1882\u001b[0m         )\n\u001b[1;32m   1883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameters \u001b[39mand\u001b[39;00m context\u001b[39m.\u001b[39mno_parameters:\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/sqlalchemy/engine/default.py:733\u001b[0m, in \u001b[0;36mDefaultDialect.do_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_executemany\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 733\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecutemany(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: table station has no column named station_id",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mstation_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m s_id\n\u001b[1;32m     20\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mjoin(station, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m, on\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mstation_id\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 21\u001b[0m data\u001b[39m.\u001b[39;49mto_sql(\u001b[39m'\u001b[39;49m\u001b[39mstation\u001b[39;49m\u001b[39m'\u001b[39;49m, con, if_exists\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mappend\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/pandas/core/generic.py:2987\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2831\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2832\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2983\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   2984\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa:E501\u001b[39;00m\n\u001b[1;32m   2985\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[0;32m-> 2987\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[1;32m   2988\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2989\u001b[0m     name,\n\u001b[1;32m   2990\u001b[0m     con,\n\u001b[1;32m   2991\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   2992\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m   2993\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   2994\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   2995\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   2996\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   2997\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   2998\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/pandas/io/sql.py:695\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(frame, DataFrame):\n\u001b[1;32m    691\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    692\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument should be either a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    693\u001b[0m     )\n\u001b[0;32m--> 695\u001b[0m \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[1;32m    696\u001b[0m     frame,\n\u001b[1;32m    697\u001b[0m     name,\n\u001b[1;32m    698\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m    699\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    700\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m    701\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m    702\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    703\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    704\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    705\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    706\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mengine_kwargs,\n\u001b[1;32m    707\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/pandas/io/sql.py:1738\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1726\u001b[0m sql_engine \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m   1728\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_table(\n\u001b[1;32m   1729\u001b[0m     frame\u001b[39m=\u001b[39mframe,\n\u001b[1;32m   1730\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1735\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1736\u001b[0m )\n\u001b[0;32m-> 1738\u001b[0m total_inserted \u001b[39m=\u001b[39m sql_engine\u001b[39m.\u001b[39;49minsert_records(\n\u001b[1;32m   1739\u001b[0m     table\u001b[39m=\u001b[39;49mtable,\n\u001b[1;32m   1740\u001b[0m     con\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnectable,\n\u001b[1;32m   1741\u001b[0m     frame\u001b[39m=\u001b[39;49mframe,\n\u001b[1;32m   1742\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1743\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   1744\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   1745\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   1746\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   1747\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mengine_kwargs,\n\u001b[1;32m   1748\u001b[0m )\n\u001b[1;32m   1750\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_case_sensitive(name\u001b[39m=\u001b[39mname, schema\u001b[39m=\u001b[39mschema)\n\u001b[1;32m   1751\u001b[0m \u001b[39mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/pandas/io/sql.py:1335\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[0;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minf cannot be used with MySQL\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1334\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1335\u001b[0m     \u001b[39mraise\u001b[39;00m err\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/pandas/io/sql.py:1325\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[0;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m \u001b[39mimport\u001b[39;00m exc\n\u001b[1;32m   1324\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39;49minsert(chunksize\u001b[39m=\u001b[39;49mchunksize, method\u001b[39m=\u001b[39;49mmethod)\n\u001b[1;32m   1326\u001b[0m \u001b[39mexcept\u001b[39;00m exc\u001b[39m.\u001b[39mSQLAlchemyError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1327\u001b[0m     \u001b[39m# GH34431\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[39m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m(1054, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown column \u001b[39m\u001b[39m'\u001b[39m\u001b[39minf(e0)?\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfield list\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m))(?#\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39m    )|inf can not be used with MySQL\u001b[39m\u001b[39m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/pandas/io/sql.py:946\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[0;34m(self, chunksize, method)\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    945\u001b[0m chunk_iter \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(arr[start_i:end_i] \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m data_list))\n\u001b[0;32m--> 946\u001b[0m num_inserted \u001b[39m=\u001b[39m exec_insert(conn, keys, chunk_iter)\n\u001b[1;32m    947\u001b[0m \u001b[39m# GH 46891\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39mif\u001b[39;00m is_integer(num_inserted):\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/pandas/io/sql.py:853\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[0;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[39mExecute SQL statement inserting data\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[39m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[1;32m    851\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    852\u001b[0m data \u001b[39m=\u001b[39m [\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(keys, row)) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m data_iter]\n\u001b[0;32m--> 853\u001b[0m result \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mexecute(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtable\u001b[39m.\u001b[39;49minsert(), data)\n\u001b[1;32m    854\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mrowcount\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1380\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1376\u001b[0m     util\u001b[39m.\u001b[39mraise_(\n\u001b[1;32m   1377\u001b[0m         exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[39m=\u001b[39merr\n\u001b[1;32m   1378\u001b[0m     )\n\u001b[1;32m   1379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1380\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\u001b[39mself\u001b[39;49m, multiparams, params, _EMPTY_EXECUTION_OPTS)\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:334\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_execute_on_connection\u001b[39m(\n\u001b[1;32m    331\u001b[0m     \u001b[39mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    332\u001b[0m ):\n\u001b[1;32m    333\u001b[0m     \u001b[39mif\u001b[39;00m _force \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_execution:\n\u001b[0;32m--> 334\u001b[0m         \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[1;32m    335\u001b[0m             \u001b[39mself\u001b[39;49m, multiparams, params, execution_options\n\u001b[1;32m    336\u001b[0m         )\n\u001b[1;32m    337\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m         \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1572\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1560\u001b[0m compiled_cache \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1561\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[1;32m   1562\u001b[0m )\n\u001b[1;32m   1564\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1565\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[1;32m   1566\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1570\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1571\u001b[0m )\n\u001b[0;32m-> 1572\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1573\u001b[0m     dialect,\n\u001b[1;32m   1574\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_compiled,\n\u001b[1;32m   1575\u001b[0m     compiled_sql,\n\u001b[1;32m   1576\u001b[0m     distilled_params,\n\u001b[1;32m   1577\u001b[0m     execution_options,\n\u001b[1;32m   1578\u001b[0m     compiled_sql,\n\u001b[1;32m   1579\u001b[0m     distilled_params,\n\u001b[1;32m   1580\u001b[0m     elem,\n\u001b[1;32m   1581\u001b[0m     extracted_params,\n\u001b[1;32m   1582\u001b[0m     cache_hit\u001b[39m=\u001b[39;49mcache_hit,\n\u001b[1;32m   1583\u001b[0m )\n\u001b[1;32m   1584\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[1;32m   1585\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[1;32m   1586\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1587\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1591\u001b[0m         ret,\n\u001b[1;32m   1592\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1943\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1940\u001b[0m             branched\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   1942\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1943\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1944\u001b[0m         e, statement, parameters, cursor, context\n\u001b[1;32m   1945\u001b[0m     )\n\u001b[1;32m   1947\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2124\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2122\u001b[0m     util\u001b[39m.\u001b[39mraise_(newraise, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me)\n\u001b[1;32m   2123\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[0;32m-> 2124\u001b[0m     util\u001b[39m.\u001b[39;49mraise_(\n\u001b[1;32m   2125\u001b[0m         sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39;49mexc_info[\u001b[39m2\u001b[39;49m], from_\u001b[39m=\u001b[39;49me\n\u001b[1;32m   2126\u001b[0m     )\n\u001b[1;32m   2127\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2128\u001b[0m     util\u001b[39m.\u001b[39mraise_(exc_info[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/sqlalchemy/util/compat.py:210\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    207\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[1;32m    209\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[1;32m    211\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1880\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1879\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1880\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_executemany(\n\u001b[1;32m   1881\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1882\u001b[0m         )\n\u001b[1;32m   1883\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameters \u001b[39mand\u001b[39;00m context\u001b[39m.\u001b[39mno_parameters:\n\u001b[1;32m   1884\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.11/site-packages/sqlalchemy/engine/default.py:733\u001b[0m, in \u001b[0;36mDefaultDialect.do_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_executemany\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 733\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecutemany(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) table station has no column named station_id\n[SQL: INSERT INTO station (time, tavg, tmin, tmax, prcp, snow, wdir, wspd, wpgt, pres, tsun, station_id, \"1230\") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)]\n[parameters: (('1985-01-01 00:00:00.000000', 1.6, 0.4, 5.9, 0.5, 0.0, 103.0, 40.7, 73.1, 1007.3, 0.0, '10015', None), ('1985-01-02 00:00:00.000000', 0.2, -0.8, 0.9, 0.0, 0.0, 35.0, 28.8, 71.3, 1012.0, 60.0, '10015', None), ('1985-01-03 00:00:00.000000', -2.7, -4.5, 0.5, 0.0, 0.0, 24.0, 34.2, 73.8, 1010.7, 60.0, '10015', None), ('1985-01-04 00:00:00.000000', -4.1, -5.2, -3.4, 0.0, 0.0, 31.0, 41.0, 78.8, 1011.0, 90.0, '10015', None), ('1985-01-05 00:00:00.000000', -5.3, -6.1, -3.3, 0.0, 0.0, 49.0, 25.9, 59.4, 1016.6, 54.0, '10015', None), ('1985-01-06 00:00:00.000000', -5.7, -7.5, -3.9, 3.5, 10.0, 131.0, 34.6, 77.8, 1009.9, 0.0, '10015', None), ('1985-01-07 00:00:00.000000', -6.7, -8.0, -5.0, 0.0, 130.0, 46.0, 32.0, 77.4, 1017.6, 366.0, '10015', None), ('1985-01-08 00:00:00.000000', -4.7, -7.7, -3.3, 4.9, 100.0, 55.0, 16.6, 58.7, 1014.3, 174.0, '10015', None)  ... displaying 10 of 13856 total bound parameter sets ...  ('2022-12-07 00:00:00.000000', 4.2, 3.9, 4.3, None, None, 107.0, 25.1, 38.9, 1022.4, None, '10015', None), ('2022-12-08 00:00:00.000000', 4.6, 4.3, 4.9, None, None, 169.0, 25.9, 38.9, 1015.8, None, '10015', None))]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "# get stations that are already in db\n",
    "try:\n",
    "    found = set(pd.read_sql_query(\n",
    "        \"\"\"\n",
    "        SELECT \"station_id\" FROM stationPOINT (7.90000 54.18330)\t\n",
    "        \"\"\",\n",
    "        con=con\n",
    "    )[\"station_id\"].tolist())\n",
    "except:\n",
    "    found = []\n",
    "\n",
    "# fetch data: TODO make multistreaded\n",
    "for _, station in tqdm(stations.iterrows(), total=stations.shape[0]):\n",
    "    s_id = station[\"station_id\"]\n",
    "    if s_id in found:\n",
    "        continue\n",
    "    daily = Daily(s_id, start=start, end=end)\n",
    "    data = daily.fetch()\n",
    "    data['station_id'] = s_id\n",
    "    data = data.join(station, how='left', on=[\"station_id\"])\n",
    "    data.to_sql('station', con, if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10416539d8bd7745bfd84da934453afb2f17a286a80737bde1b4f151ea1b0bb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
