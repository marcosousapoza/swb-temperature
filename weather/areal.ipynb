{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32701acc-24a5-4467-9fb5-f3cc33a34eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress future warning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# imports\n",
    "from collections import defaultdict\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import geopandas as gpd\n",
    "from meteostat import Stations, Daily, Point\n",
    "import numpy as np\n",
    "from src.helper import get_nuts_data\n",
    "from src.helper import get_daily_weather_data, get_daily_weather_data_loc\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "703485a1-2172-4de1-8ad3-10fe7d87f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"prod/weather.db\"\n",
    "engine = create_engine(\"sqlite:///\"+path, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df82998-c733-4eaa-a2bb-c1fe9a0270f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which tables already exist\n",
    "insp = inspect(engine)\n",
    "tables = insp.get_table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61745ab4-233d-4de9-9892-1012c725ee08",
   "metadata": {},
   "source": [
    "## Reading NUTS data\n",
    "First we read the nuts information which includes the area code and the centroid of each nuts area. This is important as we want to match each area with the SOEP dataset later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a07061b9-c289-431f-8dc0-fd4aa82f32bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading NUTS1 data\n",
      "Reading NUTS2 data\n",
      "Reading NUTS3 data\n"
     ]
    }
   ],
   "source": [
    "# add nuts data to database\n",
    "for lvl in range(1, 4):\n",
    "    print(f\"Reading NUTS{lvl} data\")\n",
    "    data = get_nuts_data(lvl)\n",
    "    data.to_sql(f'nuts{lvl}', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10388b37-ab38-45f4-981f-f616234ea68c",
   "metadata": {},
   "source": [
    "Because the `meteostat` library does not include `nuts` indexing we will need to convert the area codes to different codes. In the following the dictionaly that does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93e3906-4f9c-4564-9662-343966c2f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {\n",
    "    \"Baden-Württemberg\":\"BW\",\n",
    "    \"Bayern\":\"BY\",\n",
    "    \"Berlin\":\"BE\",\n",
    "    \"Brandenburg\":\"BB\",\n",
    "    \"Bremen\":\"HB\",\n",
    "    \"Hamburg\":\"HH\",\n",
    "    \"Hessen\":\"HE\",\n",
    "    \"Mecklenburg-Vorpommern\":\"MV\",\n",
    "    \"Niedersachsen\":\"NI\",\n",
    "    \"Nordrhein-Westfalen\":\"NW\",\n",
    "    \"Rheinland-Pfalz\":\"RP\",\n",
    "    \"Saarland\":\"SL\",\n",
    "    \"Sachsen\":\"SN\",\n",
    "    \"Sachsen-Anhalt\":\"ST\",\n",
    "    \"Schleswig-Holstein\":\"SH\",\n",
    "    \"Thüringen\":\"TH\"\n",
    "}\n",
    "\n",
    "soep_nameing = defaultdict(\n",
    "    lambda x: np.nan, {\n",
    "        \"BW\":8, \"BY\":9, \"BE\":11, \"BB\":12,\n",
    "        \"HB\":4, \"HH\":2, \"HE\":6, \"MV\":13,\n",
    "        \"NI\":3, \"NW\":5, \"RP\":7, \"SL\":10,\n",
    "        \"SN\":14, \"ST\":15, \"SH\":1, \"TH\":16\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4272d72d-a12e-4439-9f25-d95ec9b35147",
   "metadata": {},
   "source": [
    "## Downloading the Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479d17a0-5a0e-42ca-aeee-94f01b58122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define timespan of historical data search\n",
    "start = datetime(year=1984, month=1, day=1)\n",
    "end = datetime(year=2021, month=1, day=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb72a217-8a3a-455b-ace0-91861e4fb03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set cache dir to local folder\n",
    "Stations.cache_dir = './.meteocache'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e836697-7a3f-4c98-9dd3-a6d36abcc753",
   "metadata": {},
   "source": [
    "### NUTS 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6dc84e-e12f-494c-b88f-77ced118a81b",
   "metadata": {},
   "source": [
    "For reading the `nuts3` data we use a radius of 50 km around the area centroid. The reason being that some `nuts3` areas are so small they do not have stations inside them. Therefore this should yield more reliable results. The assumption is of course that climate does not vary too much in a 50 km radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c63a8-e04f-49d0-8d43-e23088bbfa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts3 = pd.read_sql_table('nuts3', con=engine)\n",
    "radius = 50000\n",
    "for _, row in tqdm(nuts3.iterrows(), total=nuts3.shape[0]):\n",
    "    # create table name\n",
    "    lvl = row['NUTS_LEVEL']\n",
    "    index = str(lvl) + row['NUTS_CODE'] + '_weather'\n",
    "    # read data according to coordinates\n",
    "    lat, lon = row['lat_times100'] / 100, row['lon_times100'] / 100\n",
    "    daily = get_daily_weather_data(lat, lon, radius, start, end)\n",
    "    # add nuts ids to table\n",
    "    daily[\"nuts_name\"] = row['NUTS_NAME']\n",
    "    # add soep_id\n",
    "    daily['sloc'] = np.nan # TODO: find which id is used here\n",
    "    # write data to database\n",
    "    if daily.shape[0] > 0:\n",
    "        daily.to_sql(index, con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b38dc-646b-48b4-ab1e-82b5a5b1956b",
   "metadata": {},
   "source": [
    "### NUTS 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "681f24ef-1a49-4e0b-8498-6a01b0edffc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 16/16 [33:20<00:00, 125.05s/it]\n"
     ]
    }
   ],
   "source": [
    "nuts1 = pd.read_sql_table('nuts1', con=engine)\n",
    "for _, row in tqdm(nuts1.iterrows(), total=nuts1.shape[0]):\n",
    "    # create table name\n",
    "    lvl = row['NUTS_LEVEL']\n",
    "    index = str(lvl) + row['NUTS_CODE'] + '_weather'\n",
    "    nuts_name = row['NUTS_NAME']\n",
    "    daily = get_daily_weather_data_loc(\n",
    "        loc=(\"DE\", rename[nuts_name]),\n",
    "        start = start,\n",
    "        end = end\n",
    "    )\n",
    "    # add nutsname to table\n",
    "    daily[\"nuts_name\"] = nuts_name\n",
    "    # add soep_id\n",
    "    daily['sloc'] = soep_nameing[rename[ nuts_name ]]\n",
    "    # write data to database\n",
    "    if daily.shape[0] > 0:\n",
    "        daily.to_sql(index, con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c64dc5f-8dfd-4fd4-b0bb-069aa83811e8",
   "metadata": {},
   "source": [
    "### NUTS 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ca607d0-0914-4990-b1f5-9b98e68bb098",
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl = 0\n",
    "index = str(lvl) + 'DE' + '_weather'\n",
    "daily = get_daily_weather_data_loc(\n",
    "    loc=(\"DE\",),\n",
    "    start = start,\n",
    "    end = end\n",
    ")\n",
    "# add nutsname to table\n",
    "daily[\"nuts_name\"] = \"DE\"\n",
    "# add soep_id\n",
    "daily['sloc'] = np.nan\n",
    "# write data to database\n",
    "if daily.shape[0] > 0:\n",
    "    daily.to_sql(index, con=engine, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 | packaged by conda-forge | (main, Oct 25 2022, 06:24:40) [GCC 10.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "10416539d8bd7745bfd84da934453afb2f17a286a80737bde1b4f151ea1b0bb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
